<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="TermsProjectSettings">
    <currentTermsLanguage>en</currentTermsLanguage>
    <terms>
      <map>
        <entry key="en">
          <value>
            <map>
              <entry key="79769431">
                <value>
                  <list>
                    <Term value="Q-learning" definition="Q-learning is a reinforcement learning algorithm to learn the value of an action in a particular state." />
                    <Term value="Markov decision process (FMDP)" definition="For any finite Markov decision process (FMDP), Q-learning finds an optimal policy in the sense of maximizing the expected value of the total reward over any and all successive steps, starting from the current state." />
                    <Term value="Bellman equation" definition="The Bellman equation is a recursive equation that updates the Q value using the weighted average of the current value and the new information in Q-learning." />
                    <Term value="episode" definition="An episode of the Q-learning algorithm ends when the next state is a terminal state." />
                  </list>
                </value>
              </entry>
              <entry key="350619739">
                <value>
                  <list>
                    <Term value="Reinforcement Learning" definition="Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by performing actions and receiving rewards over time." />
                    <Term value="Q-learning" definition="Q-learning is an off-policy reinforcement learning algorithm that seeks to find the best action to take given the current state by using a Q-table." />
                    <Term value="Q-Learning" definition="Q-learning is an off-policy reinforcement learning algorithm that seeks to find the best action to take given the current state by using a Q-table." />
                    <Term value="curse of dimensionality" definition="The curse of dimensionality refers to the challenges faced when a problem's state or action space grows exponentially in size, making it difficult to solve efficiently." />
                    <Term value="delayed effect" definition="In reinforcement learning, a delayed effect occurs when the action taken at a certain time step results in a reward that appears after a number of subsequent steps." />
                  </list>
                </value>
              </entry>
              <entry key="539250567">
                <value>
                  <list>
                    <Term value="get_random_next_state" definition="A function that accepts the current state (cell number), an F-matrix, and the number of states (cells) and returns one of the possible next states for this cell at random." />
                    <Term value="numpy.random.randint" definition="A function in the numpy library used to return random integers from a given low (inclusive) to a high (exclusive) range." />
                    <Term value="random.choice" definition="A function in Python's random module used to return a randomly selected element from a non-empty sequence." />
                    <Term value="random.randint" definition="A function in Python's random module that produces a random integer within a specified inclusive range." />
                    <Term value="random.shuffle" definition="A function in Python's random module used to randomly shuffle the elements of a list in place." />
                  </list>
                </value>
              </entry>
              <entry key="675317924">
                <value>
                  <list>
                    <Term value="Maze.maze_grid" definition="`Maze.maze_grid` is a Numpy array of `Cell` objects representing the grid of a Maze." />
                    <Term value="Feasibility matrix" definition="A Feasibility matrix is a table where cells of a maze are represented with numbers. Rows and columns represent cells, and values indicate access between cells, using 0 for inaccessible and 1 for accessible." />
                  </list>
                </value>
              </entry>
              <entry key="830716025">
                <value>
                  <list>
                    <Term value="Q-matrix" definition="A matrix where row indices represent 'from' cells and column indices represent 'to' cells, used to determine transitions in tasks like maze navigation." />
                    <Term value="np.argmax()" definition="A function in NumPy that returns the index of the largest value in an input vector." />
                  </list>
                </value>
              </entry>
              <entry key="861503970">
                <value>
                  <list>
                    <Term value="Q-learning algorithm" definition="Q-learning algorithm is a reinforcement learning technique where the agent updates a Q-matrix by maximizing cumulative rewards for state-action pairs." />
                    <Term value="max_Q" definition="max_Q refers to the largest Q value of a transition from the next state to any next-next state, used to update the Q-matrix." />
                    <Term value="Q-matrix" definition="Q-matrix is a table used in Q-learning to store the values of state-action pairs representing the agent's learned rewards." />
                    <Term value="max_epochs" definition="max_epochs is a maximum loop control variable that limits the number of random starting positions in Q-learning to ensure the algorithm does not run indefinitely." />
                  </list>
                </value>
              </entry>
              <entry key="865980494">
                <value>
                  <list>
                    <Term value="Reinforcement Learning (RL)" definition="Reinforcement Learning is an area of machine learning where an agent learns to make decisions by performing actions in an environment to maximize a notion of cumulative reward." />
                    <Term value="Q-learning" definition="Q-learning is a model-free Reinforcement Learning algorithm that seeks to find the best action to take given the current state by updating a Q-table iteratively based on rewards and penalties." />
                    <Term value="Q-table" definition="A Q-table is a data structure that stores Q-values, which are used in Q-learning to represent the expected utility of taking a given action in a given state." />
                    <Term value="NumPy" definition="NumPy is a powerful Python library used for numerical computing and provides array objects and various operations to manipulate these arrays." />
                  </list>
                </value>
              </entry>
              <entry key="882652180">
                <value>
                  <list>
                    <Term value="numpy.where" definition="In Python, numpy.where is a function used to replace or modify elements in an array based on a condition." />
                    <Term value="__init__" definition="The __init__ method is a special method in Python classes, called the constructor, used to initialize new objects of that class." />
                    <Term value="find_reachable_neighbors" definition="The find_reachable_neighbors function identifies cells that can be reached from a specific starting cell in a maze or grid structure." />
                  </list>
                </value>
              </entry>
              <entry key="1233612350">
                <value>
                  <list>
                    <Term value="find_reachable_neighbors" definition="A function that accepts a maze and a cell in that maze, and returns a list of accessible neighbor Cell objects which do not have a shared wall with the given cell." />
                    <Term value="maze.delta" definition="A dictionary used to iterate over potential neighboring cells in a maze." />
                    <Term value="cell.walls" definition="A dictionary used to determine the presence or absence of walls between a cell and its neighbors." />
                  </list>
                </value>
              </entry>
              <entry key="1386230563">
                <value>
                  <list>
                    <Term value="Q-matrix" definition="The Q-matrix is a matrix where row indices represent the 'from' cells and column indices represent the 'to' cells, storing quality values for transitions." />
                    <Term value="Q-learning algorithm" definition="Q-learning is an algorithm that updates state-action values (Q-values) using the Bellman equation to optimize decision-making." />
                    <Term value="Bellman equation" definition="The Bellman equation is a recursive mathematical formula used to calculate the optimal policy by solving for Q-values in decision processes." />
                  </list>
                </value>
              </entry>
              <entry key="1492990870">
                <value>
                  <list>
                    <Term value="Q-learning" definition="Q-learning is a model-free off-policy reinforcement learning algorithm to learn the value of an action in a particular state. It does not require a model of the environment and can handle problems with stochastic transitions and rewards." />
                    <Term value="SARSA" definition="State–action–reward–state–action (SARSA) is an on-policy variation of Q-learning where the update equation depends on the current state, current action, reward obtained, next state, and next action." />
                    <Term value="Monte Carlo methods" definition="Monte Carlo methods are a class of computational algorithms that rely on repeated random sampling to obtain numerical results, commonly used in optimization, numerical integration, and generating draws from a probability distribution." />
                  </list>
                </value>
              </entry>
              <entry key="1501794337">
                <value>
                  <list>
                    <Term value="Environment" definition="The entire maze, consisting of a set of cells with walls between some of them, or a set of states. Typically stated as a Markov decision process (MDP)." />
                    <Term value="environment" definition="The entire maze, consisting of a set of cells with walls between some of them, or a set of states. Typically stated as a Markov decision process (MDP)." />
                    <Term value="states" definition="A single element in the environment, represented as a cell in this example." />
                    <Term value="stated" definition="A single element in the environment, represented as a cell in this example." />
                    <Term value="State" definition="A single element in the environment, represented as a cell in this example." />
                    <Term value="state" definition="A single element in the environment, represented as a cell in this example." />
                    <Term value="Agent" definition="An entity that can interact with the environment via actions and exists in a state." />
                    <Term value="agent" definition="An entity that can interact with the environment via actions and exists in a state." />
                    <Term value="actions" definition="A function an agent can invoke from a given state to move to another state, such as move up, down, left, or right." />
                    <Term value="Action" definition="A function an agent can invoke from a given state to move to another state, such as move up, down, left, or right." />
                    <Term value="action" definition="A function an agent can invoke from a given state to move to another state, such as move up, down, left, or right." />
                    <Term value="Reward" definition="The reinforcement (positive or negative) received under each transition." />
                    <Term value="rewards" definition="The reinforcement (positive or negative) received under each transition." />
                    <Term value="reward" definition="The reinforcement (positive or negative) received under each transition." />
                    <Term value="Q-learning" definition="A common form of RL where the optimal policy is learned implicitly through the Q-function, which solves the Bellman equation." />
                    <Term value="Q-table" definition="A table that records the expected value of a state when an action is taken, mapping a reward to every (state, action) pair." />
                  </list>
                </value>
              </entry>
              <entry key="1508370340">
                <value>
                  <list>
                    <Term value="nditer" definition="A Numpy method used for efficiently iterating over multi-dimensional arrays." />
                  </list>
                </value>
              </entry>
              <entry key="1651092545">
                <value>
                  <list>
                    <Term value="Q-learning" definition="Q-learning is a reinforcement learning algorithm that works to find the optimal action-selection policy by learning the value of an action in a particular state." />
                    <Term value="learning rate" definition="In Q-learning, the learning rate (denoted as α) determines how much the learner updates the value of a state-action pair with new information." />
                  </list>
                </value>
              </entry>
              <entry key="1829181205">
                <value>
                  <list>
                    <Term value="NumPy array" definition="A NumPy array is a powerful N-dimensional array object which is part of the NumPy library in Python. It is used for numerical computations and data manipulation." />
                  </list>
                </value>
              </entry>
              <entry key="1958163441">
                <value>
                  <list>
                    <Term value="Reinforcement Learning" definition="Reinforcement learning (RL) is one of three basic machine learning paradigms where a model learns from interactions with an environment to maximize a reward function without requiring correct labels for actions upfront." />
                    <Term value="reinforcement learning" definition="Reinforcement learning (RL) is one of three basic machine learning paradigms where a model learns from interactions with an environment to maximize a reward function without requiring correct labels for actions upfront." />
                    <Term value="Reinforcement learning" definition="Reinforcement learning (RL) is one of three basic machine learning paradigms where a model learns from interactions with an environment to maximize a reward function without requiring correct labels for actions upfront." />
                    <Term value="deep Q-learning" definition="Deep Q-learning is a method under reinforcement learning, as patented by Google's DeepMind, used to solve problems like maze navigation by finding an optimal sequence of actions to maximize accumulated rewards." />
                    <Term value="agent" definition="In reinforcement learning, an agent is an entity that operates in an environment and explores and exploits past experiences to achieve the goal of maximizing rewards." />
                    <Term value="reward function" definition="In reinforcement learning, a reward function is a mechanism that provides feedback in the form of rewards and penalties to guide the agent towards achieving its goal." />
                    <Term value="states" definition="States represent the different configurations or positions the agent can occupy in the environment while working towards a pre-defined final state in reinforcement learning." />
                    <Term value="state" definition="States represent the different configurations or positions the agent can occupy in the environment while working towards a pre-defined final state in reinforcement learning." />
                  </list>
                </value>
              </entry>
              <entry key="1976455572">
                <value>
                  <list>
                    <Term value="Q-matrix" definition="A matrix used in reinforcement learning to store the 'quality' of taking a particular action in a given state, contributing to the agent's goal achievement." />
                    <Term value="F-matrix" definition="A matrix representing the connectivity of states (cells) in a task, used to determine possible next states from a given state." />
                    <Term value="get_possible_next_states" definition="A function that uses the F-matrix to determine and return a list of states (cells) that can be reached from a given state." />
                  </list>
                </value>
              </entry>
            </map>
          </value>
        </entry>
      </map>
    </terms>
    <termsVersions>
      <map>
        <entry key="en" value="18" />
      </map>
    </termsVersions>
  </component>
</project>